# scripts/arifos_caged_llm_zkpc_demo.py
"""
arifOS Caged LLM Demo with zkPC (v36Ω)

This script demonstrates the full governed pipeline:

1. Take a user query (from CLI).
2. Retrieve relevant canon from Cooling Ledger (L1) via vault_retrieval.
3. Call a mock "LLM" to generate an answer (you can replace this with a real model).
4. Run zkPC runtime:
   - Build care_scope,
   - Compute metrics (stub),
   - Run @EYE COOL checks (stub),
   - Build zkPC receipt,
   - Commit to Cooling Ledger + update Merkle root.
5. Print a summary:
   - Answer,
   - zkPC receipt_id,
   - vault_commit (hash, previous_hash, merkle_root).

Usage (from repo root):

    python -m scripts.arifos_caged_llm_zkpc_demo --query "Explain the 'correct ≠ complete' law."

In future, you can:
- Replace `mock_llm_call()` with a real LLM integration,
- Expand metrics/@EYE logic,
- Add 888 Judge SEAL flow on top of zkPC receipts.
"""

from __future__ import annotations

import argparse
import sys
from typing import Any, Dict, List

from arifos_core.vault_retrieval import RetrievalQuery, retrieve_canon_entries
from arifos_core.zkpc_runtime import ZKPCContext, run_zkpc_for_answer


def mock_llm_call(prompt: str, retrieved_canon: List[Dict[str, Any]]) -> str:
    """
    Placeholder for a real LLM call.

    For now, this just echoes the query and mentions how many canon entries were retrieved.
    You are expected to replace this with a call to Claude / ChatGPT / SEA-LION, etc.
    """
    canon_ids = [c.get("id") for c in retrieved_canon if isinstance(c, dict)]
    return (
        "MOCK ANSWER:\n"
        f"- User query: {prompt}\n"
        f"- Retrieved {len(retrieved_canon)} canon entries: {canon_ids}\n\n"
        "In a real deployment, this text would be generated by a governed LLM "
        "that reads both the user query and the retrieved canon entries."
    )


def main() -> int:
    parser = argparse.ArgumentParser(
        description="arifOS caged LLM demo with zkPC + Cooling Ledger."
    )
    parser.add_argument(
        "--query",
        type=str,
        required=True,
        help="User query / case description.",
    )
    parser.add_argument(
        "--high-stakes",
        action="store_true",
        help="Mark this query as high-stakes (affects zkPC context).",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=5,
        help="Maximum number of canon entries to retrieve from Cooling Ledger.",
    )
    parser.add_argument(
        "--no-commit",
        action="store_true",
        help="Do not commit the zkPC receipt to the ledger (dry run).",
    )
    args = parser.parse_args()

    user_query = args.query
    high_stakes = args.high_stakes
    limit = max(1, args.limit)
    commit = not args.no_commit

    print("\n[arifos_caged_llm_zkpc_demo] === INPUT ===")
    print(f"Query      : {user_query}")
    print(f"High-stakes: {high_stakes}")
    print(f"Ledger limit: {limit}")
    print(f"Commit     : {commit}")

    # Step 1: Retrieve canon entries from Cooling Ledger
    retrieval_query = RetrievalQuery(
        text=user_query,
        types=None,   # can restrict later, e.g. ["999_SEAL", "PROPOSED_CANON"]
        tags=None,    # can add tags like ["maruah", "trauma", "religion"]
        high_stakes=high_stakes,
        limit=limit,
    )
    retr_result = retrieve_canon_entries(retrieval_query)

    print("\n[arifos_caged_llm_zkpc_demo] === RETRIEVAL ===")
    print(f"Total ledger entries  : {retr_result.debug_info['total_entries']}")
    print(f"Candidates after filter: {retr_result.debug_info['candidates']}")
    print(f"Returned              : {retr_result.debug_info['returned']}")

    retrieved_canon = retr_result.entries
    for i, e in enumerate(retrieved_canon):
        print(f"  [{i}] id={e.get('id')} type={e.get('type')}")

    # Step 2: Call (mock) LLM with query + canon
    print("\n[arifos_caged_llm_zkpc_demo] === MOCK LLM CALL ===")
    answer = mock_llm_call(user_query, retrieved_canon)
    print(answer)

    # Step 3: Build zkPC context
    ctx = ZKPCContext(
        user_query=user_query,
        retrieved_canon=retrieved_canon,
        high_stakes=high_stakes,
        meta={},
    )

    # Step 4: Run zkPC runtime (all phases) and optionally commit to Cooling Ledger
    print("\n[arifos_caged_llm_zkpc_demo] === zkPC RUNTIME ===")
    receipt = run_zkpc_for_answer(ctx, answer, verdict="SEAL", commit=commit)

    receipt_id = receipt.get("receipt_id")
    vault_commit = receipt.get("vault_commit", {})

    print(f"zkPC receipt_id : {receipt_id}")
    print("vault_commit    :")
    print(f"  ledger      : {vault_commit.get('ledger')}")
    print(f"  hash        : {vault_commit.get('hash')}")
    print(f"  previous_hash: {vault_commit.get('previous_hash')}")
    print(f"  merkle_root : {vault_commit.get('merkle_root')}")

    if commit:
        print("\n[arifos_caged_llm_zkpc_demo] DONE (committed to ledger).")
        print(
            "You can now inspect:\n"
            "  - cooling_ledger/L1_cooling_ledger.jsonl (new zkpc_receipt entry)\n"
            "  - cooling_ledger/L1_merkle_root.txt (updated Merkle root)\n"
            "  - use scripts/propose_canon_from_receipt.py to draft EUREKA canon from this receipt."
        )
    else:
        print("\n[arifos_caged_llm_zkpc_demo] DONE (dry run, no ledger commit).")

    return 0


if __name__ == "__main__":
    sys.exit(main())
